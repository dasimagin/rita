train:
    # optimizer
    learning_rate: 0.0001
    max_grad_norm: 50

    # a3c
    agents_n: 16
    update_agent_frequency: 60
    sample_entropy: false
    sample_lr: false

    # loss
    gamma: 0.99 # train discount coef
    tau: 1.00 # GAE parameter
    value_weight: 0.5
    entropy_weight: 0.001

    # intrinsic rewards
    curiosity_weight: 0.001

    # auxiliary tasks
    use_pixel_control: false
    use_reward_prediction: false
    pc_coef: 0.001

    # backups
    save_frequency: 5

environment:
    env_type: "dmlab"
    env_name: "nav_maze_random_goal_01"
    skip_frames: 0
    clip_rewards: false
    stack_frames: 1
    frame_h: 84
    frame_w: 84
    normalize_env: true
    noop_max: null
    fps: 15
    episode_length_sec: 60
    bot_count: null
    bot_skill: null
