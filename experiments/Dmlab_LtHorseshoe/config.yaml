train:
    # optimizer
    learning_rate: 0.0001
    max_grad_norm: 50

    # a3c
    agents_n: 32
    update_agent_frequency: 40
    sample_entropy: true

    # loss
    gamma: 0.99 # train discount coef
    tau: 1.00 # GAE parameter
    value_weight: 0.5
    entropy_weight: 0.001

    # intrinsic rewards
    curiosity_weight: 0.01

    # backups
    save_frequency: 3

environment:
    env_type: "dmlab"
    env_name: "lt_horseshoe_color"
    skip_frames: 0
    clip_rewards: true
    stack_frames: 1
    frame_h: 84
    frame_w: 84
    normalize_env: true
    noop_max: null
    fps: 15
    episode_length_sec: 600
